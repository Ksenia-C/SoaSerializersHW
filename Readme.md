Проект для замера времени сериализации/десериализации популярных форматов. Код запускается на c++, и в качестве форматов выбраны

1.   __text__. Нативный вариант сериализации - boost, text_serializer

2.   __xml__. XML - boost, xml_serializer

3.   __json__. JSON - boost, json

4.   __proto__. Google Protocol Buffers - protocol compiler, c++

5.   __avro__. Apache Avro - avro-cpp

6.   __yaml__. YAML - yaml-cpp

7.   __msg__. MessagePack - msgpack-cxx 

Локально можно запустить только один из форматов через Makefile. Но для этого может понадобится предустановить библиотеки, поэтому рекомендуется запускать через docker-compose. Но если очень хочется, список зависимостей ниже, и можно подсматривать в соответствующий dockerfile.

Для проверки создается структура

```cpp
struct TestData
{
    std::string one_str;

    std::vector<int> one_array;

    std::map<std::string, int> one_map;

    uint64_t u64 = 0;

    double f64 = 0.0;
}
```
Которую можно заполнить небольшими или рандомными большими данными. После чего для конкретного формата несколько раз запускается сериализация структуры с сохранением в файл, и ее десериализация. Так как часто базовая структура должна быть дополнена функциями, чтобы можно было использовать библиотеки, то различные копирования, перемещения данных и создание файла, куда сохраняют промежуточные результаты, не учитывается в замерах, где это возможно.

Вывод программы:

```{Измеряемые часы}: {Формат сериализации} – {Размер сериализованной структуры/объекта в байтах} – {Время сериализации} – {Время десериализации}```

Пример:
```
WALL: xml - 252 - 0.026649ms - 0.035065ms
CPU: xml - 252 - 0.027447ms - 0.036437ms
```

Измеряемые часы могут быть wall и cpu. Каждый вариант запускается отдельно и берется среднее, поэтому между собой числа не связаны.

# Запуск

```sudo docker-compose up``` подтянет образы из docker hub и запустит контейнеры. 

Если нужно пересобирать образы локально, можно скопировать оба файла из __dev__ в корневую папку (осторожно с конфликтом имет docker-compose.yaml). Команда дальше рассчитаны на такое расположение файлов.

Cначала нужно собрать

```bash
sudo docker build . --tag serializer/common:1.0 -f Dockerfiles/restbed.Dockerfiles
sudo docker build . --tag serializer/boost:1.0 -f Dockerfiles/boost.Dockerfile
```
для удобства можно собрать через ```sudo docker-compose -f docker-compose.build.yaml build```

А затем
```bash
sudo docker-compose -d up
```

Чтобы можно было оценить примерно

время сборки ```sudo docker-compose -f docker-compose.build.yaml build --no-cache```: 293 + 832 секунд

время сборки  ```sudo docker-compose build --no-cache```:  627 секунд

но может сильно отличаться.

# Формат запросов

После чего можно отправлять запросы на localhost. Например чтобы посмотреть замеры для xml формата:
```http://localhost:5000/get_result```

Также есть proxy сервер к которому можно обращаться через
```http://localhost:6000/get_result/xml```

Порты можно найти в docker-compose.yaml. Названия, которые можно передавать после get_result для proxy выделены __bold__ в списке выше. Также если нужно сменить порт, можно исправить его в __docker-compose.yaml__, после пересобрать proxy.Dockerfile c __--no-cache__ и запустить __docker-compose up__ (так быстрее всего). Как пересобрать любой образ можно найти в его Dockerfile первой строчкой в комментариях. Конечно, для этого нужно будет поменять docke-compose файлы как написано выше.

Также можно отправить ```http://localhost:6000/get_result/all```. Тогда прокси сервер сходит в каждый сервер и вернет все их результаты одним ответом.

Также можно задать размер структуры. Например
```http://localhost:5000/get_result?test_size=1000``` будет работать со структурой у которой размеры one_str, one_map и one_array будет равны 1000 и заполнены некоторыми данными. Размер структуры в байтах будет печатся в ответе, поэтому test_size скорее относительная величина.

Также есть файл __example.cpp__ где вместе собраны все форматы и на котором тестился код сериализации. Воспринимайте как readme, чтобы не открывать кучу файлов.

# Локальный запуск
Для этого выполните ```make build_xml && make run``` - чтобы запустить похожий сервер для xml. Proxy сервер не поддерживается. Также сборка будет дебажной, потому что это скорее поиграться и для разработки, нежели пользоваться. Дефолтный порт - 5000. Вместо xml можно подставлять __bold слова__ из списка из начала.

## Зависимости
boost.1.82 - для text, json, xml. https://www.boost.org/doc/libs/1_82_0/more/getting_started/unix-variants.html.

proto-compiler - для protobuf. Может ставится как пакет protobuf, если arch. Или смотрите в https://protobuf.dev/downloads/.

restbed - для серверов. https://github.com/Corvusoft/restbed.git. Склонировать в директорию проекта, установить через make install как в инструкции с репозитория, и cкопировать so файлы из restbed/distribution/library в /usr/local/lib/. Можете посмотреть в __Dockerfiles/restbed.Dockerfile__

avro-cpp, yaml-cpp, msgpack-cxx - могут ставится как пакеты (если arch), но легко гуглятся и дальше смотри по инструкциям сайтов/репозиториев. На самом деле другие способы не проверялись, но avro-cpp в __Dockerfiles/avro.Dockerfile__ устанавливается через makepkg.


# немного про то, как докер образы строятся



Eсть класс __Serializer__, который описан в 7 файлах. В них буквально определен один метод как сериализировать, десериализировать и замерять время для одного запуска, и возможно описание структур которые нужны для библиотек. После создает symlink serializer.hpp, на конкретный файл с форматом, который уже включается в коде сервера. В самих докерах копируется только один файл для своего формата и устанавливаются нужные библиотеки, поэтому в них нет лишних файлов, не связанных с конкретным форматом. А также restbed (для написания сервера) и boost имеют свои отдельные образы, так как часто используются. docker-compose не позволяет только собрать образы без запуска контейнеров, и эти базовые образы мне не нужно запускать, поэтому docker-compose файлов 2. И получается что локально можно запустить только один формат, а для этого proxy сервер не нужен. Конечно можно было соорудить фабрику сериализаторов, но это уже второстепенная задача и немного усложняет докер образы.


### если будете смотреть в dockerfiles
Пояснение, почему в самом базовом dockerfile стоит строчка FROM archlinux:latest, а не привычная ubuntu. Весь код писался на ноуте с arch linux, а это означает все последние версси всех пакетов по дефолту. А в ubuntu некоторые пакеты были слишком старыми и из-за этого возникали проблемы. Частично я не хотела их решать прямо сейчас, что в итоге привело меня к archlinux:latest. Причем одна из проблем была очень странной (если не добавить санитайзеры, то компилятор не мог найти функции из библиотек с динамической линковкой, что у меня локально вообще не воспроизводилось и это бред какой-то. Возможно я знаю почему, но не проверила до конца). 

### не особо важная мысль просто так
Расписывать раздел #Зависимости было очень странно, потому что в основном пишут инструкции для ubuntu/mac/windows, возможно fedora. И как пользователь arch приходится каждый раз искать соответствующий пакет или целую инструкцию для своего дистрибутива. А здесь получилось наоборот. Хотя я честно изначально взяла образ ubuntu как базовый.
